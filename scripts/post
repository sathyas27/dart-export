#!/bin/bash

###############
# DART Preprocessing V0
###############

##### START sbatch setup #####

# Selecting a partition
#SBATCH -p debug

## Unless you want to request the debug and scavenger partitions,
## Slurm will automatically assign job to the correct partition

# Account to charge (defaults to low priority)
# High Priority
#SBATCH -A astronomy-hi

# How long the job will run (H:M:S)
#SBATCH -t 00:01:00

# Node and core requirements
## Number of MPI task
#SBATCH --ntasks=1

## Number of CPU cores to use for each task
#SBATCH --cpus-per-task=1

# Memory requirements
# The default is 6GB per CPU core
# sbatch command specifies memory in mb.
#SBATCH --mem-per-cpu=16384


# Whether or not other jobs can be on the same node
## Hurts performance while decreasing SU usage
## Increased performance and SU usage
#SBATCH --exclusive

# Do not inherit environment of process running sbatch command
# Setting up the environment in this script is more reproducible.
#SBATCH --export=None

# Job name
#SBATCH --job-name=post-dart

# stdout and stderr merged to stdout/OUTFILE
#SBATCH -o OUTFILE

# Email address and mailing preferences
#SBATCH --mail-user=slurmlogger@gmail.com
#SBATCH --mail-type=ALL
#SBATCH --mail-type=TIME_LIMIT_50
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-type=TIME_LIMIT_90
#SBATCH --mail-type=TIME_LIMIT
##### END sbatch setup #####

. ~/.profile

##### START module commands #####
module purge
module load envi/5.4.1
# module load python 3.8.2


source /home/${USER}/.bashrc
source activate hyperion
sleep 10
##### END module commands #####

##### START job commands #####
# Initial parameters

MAIN_SCRIPT='ExtractImage.py'


JOB_LOG='log-post'


# Run the code
which python >> $JOB_LOG 2>&1
python "${MAIN_SCRIPT}" >> $JOB_LOG 2>&1


##### END job commands #####

